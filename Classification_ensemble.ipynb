{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_ensemble.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niveditathakur/Classification/blob/master/Classification_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UeZTkX93uKaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load all the libraries \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection, preprocessing \n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder,  StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, log_loss, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from keras.utils import np_utils\n",
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
        "#ensemble classsifier\n",
        "from mlxtend.classifier import EnsembleVoteClassifier\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Conv1D, BatchNormalization, MaxPooling1D, Activation, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNLD_lR9uR2N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# number of folds required for cross validataion\n",
        "num_folds = 3\n",
        "\n",
        "        \n",
        "#classifiers used -list of all the classifiers used\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(5),\n",
        "    SVC(gamma='scale',kernel=\"rbf\", C=0.025, probability=True),\n",
        "    DecisionTreeClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    LogisticRegression(penalty = 'l2', C = 10, random_state=0),\n",
        "    RidgeClassifier()]\n",
        "\n",
        "\n",
        "#min max scalar - normalize the features to range -1 and 1 \n",
        "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "\n",
        "#Fxn to find confidence interval for cv classification\n",
        "def CI_find(acc, alpha=0.95):\n",
        "    # confidence intervals alpha = 0.95\n",
        "    \n",
        "    p         =   ((1.0-alpha)/2.0) * 100\n",
        "    lower     =   max(0.0, np.percentile(acc, p))\n",
        "    p         =   (alpha+((1.0-alpha)/2.0)) * 100\n",
        "    upper     =   min(1.0, np.percentile(acc, p))\n",
        "    acc_std   =   ((upper - lower) / 2)*100\n",
        "\n",
        "    return( np.mean(acc)*100, acc_std )\n",
        "\n",
        "\n",
        "# Function to do  cross validation\n",
        "def Fxn_CV(Input, Output): \n",
        "    \n",
        "    # scale the input \n",
        "    x_scaled = min_max_scaler.fit_transform(Input) \n",
        "    \n",
        "    # Logging for Visual Comparison use a  pandas dataframe \n",
        "    log_cols=[\"Classifier Name\",\"Acc (MS)\", \"Acc-SD (MS)\", \"AUROC (MS)\", \"AUROC-SD (MS)\" ,\n",
        "                                \"Acc\", \"Acc-SD\", \"AUROC\", \"AUROC-SD\"] \n",
        "    log = pd.DataFrame(columns=log_cols)\n",
        "    \n",
        "    #KFolds using sklearn\n",
        "    kfold = model_selection.KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "    \n",
        "    \n",
        "    for clf in classifiers:\n",
        "        name     = clf.__class__.__name__\n",
        "        \n",
        "        # use sklearn' in build cross_val_score for cross validation\n",
        "        #use accuracy as metric for performance\n",
        "        acc_res  = model_selection.cross_val_score(clf, Input, Output, cv=kfold, \n",
        "                                                   scoring='accuracy')\n",
        "        \n",
        "        #use Area under roc curve as metric for performance\n",
        "        auc_res  = model_selection.cross_val_score(clf,  Input, Output, cv=kfold, \n",
        "                                                  scoring='roc_auc') \n",
        "        \n",
        "        #create empty lists for Acc and AUROC derived using only kfold\n",
        "        score = list()\n",
        "        acc   = list()\n",
        "        \n",
        "        for train_index, test_index in kfold.split(Input):\n",
        "          \n",
        "            X_train, X_test    = Input[ train_index, :], Input[test_index,:]\n",
        "            y_train, y_test    = Output[train_index],    Output[test_index]\n",
        "            \n",
        "            clf                = clf.fit(X_train, y_train)\n",
        "\n",
        "            y_pred             = clf.predict(X_test)\n",
        "            acc1               = accuracy_score(y_test, y_pred)\n",
        "            acc.append(acc1)\n",
        "             \n",
        "            tt           = y_pred.astype(int)\n",
        "            org          = y_test.astype(int) \n",
        "            \n",
        "            #one hot encoding for AUROC\n",
        "            one_hot_pred = np_utils.to_categorical(tt) ;\n",
        "            one_hot_org  = np_utils.to_categorical(org) ;\n",
        "            \n",
        "            score.append(roc_auc_score(one_hot_org, one_hot_pred))\n",
        "        \n",
        "\n",
        "        acc_mean, acc_std     = CI_find(acc, alpha=0.95)\n",
        "        auroc_mean, auroc_std = CI_find(score, alpha=0.95)\n",
        "        \n",
        "        \n",
        "        #enter the data to the pandas dataframe\n",
        "        log_entry  =  pd.DataFrame([[name, acc_res.mean()*100, acc_res.std()*100, \n",
        "                                     auc_res.mean(),  auc_res.std(), \n",
        "                                     acc_mean, acc_std, \n",
        "                                     auroc_mean/100, auroc_std/100 ]], columns=log_cols)        \n",
        "        log        =  log.append(log_entry)\n",
        "\n",
        "    return(log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4CSjTHKyuVhv",
        "colab_type": "code",
        "outputId": "4727a249-7796-47c9-af1e-de842595a294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "#load the breast cancer data - two class classification problem\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer_data = load_breast_cancer()\n",
        "\n",
        "data = cancer_data.data   # features \n",
        "labels = cancer_data.target # labels \n",
        "\n",
        "log = Fxn_CV(data, labels)\n",
        "print(log)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 Classifier Name   Acc (MS)  Acc-SD (MS)  AUROC (MS)  \\\n",
            "0           KNeighborsClassifier  92.618583     0.859667    0.953154   \n",
            "0                            SVC  62.733686     4.251442    0.970136   \n",
            "0         DecisionTreeClassifier  91.394226     2.430917    0.924584   \n",
            "0             AdaBoostClassifier  95.958415     1.311157    0.990327   \n",
            "0         RandomForestClassifier  94.902998     1.083060    0.984464   \n",
            "0     GradientBoostingClassifier  95.960271     1.622955    0.992257   \n",
            "0                     GaussianNB  93.846654     1.393031    0.986492   \n",
            "0     LinearDiscriminantAnalysis  95.254804     0.011815    0.990850   \n",
            "0  QuadraticDiscriminantAnalysis  95.607537     0.487026    0.991087   \n",
            "0             LogisticRegression  94.903926     1.310681    0.990712   \n",
            "0                RidgeClassifier  94.905783     0.983241    0.990913   \n",
            "\n",
            "   AUROC-SD (MS)        Acc    Acc-SD     AUROC  AUROC-SD  \n",
            "0       0.004775  92.618583  1.000000  0.915940  0.009094  \n",
            "0       0.007599  62.733686  4.854497  0.500000  0.000000  \n",
            "0       0.039723  92.973174  1.236772  0.920947  0.020759  \n",
            "0       0.005796  95.958415  1.500000  0.952943  0.013233  \n",
            "0       0.003605  94.899285  2.518519  0.944784  0.021609  \n",
            "0       0.003613  96.135710  1.750000  0.953426  0.022033  \n",
            "0       0.008168  93.846654  1.518519  0.928885  0.011220  \n",
            "0       0.003598  95.254804  0.011905  0.936918  0.009415  \n",
            "0       0.003169  95.607537  0.490741  0.954735  0.004661  \n",
            "0       0.000557  94.903926  1.500000  0.941551  0.012731  \n",
            "0       0.001968  94.905783  0.990741  0.934559  0.022908  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2cDRMCmuuZOY",
        "colab_type": "code",
        "outputId": "b5432e18-c42a-40f4-d71b-8325f682f3f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "#use ensemble of classifiers\n",
        "\n",
        "clf1  = LogisticRegression(random_state=0)\n",
        "clf2  = RandomForestClassifier(random_state=0)\n",
        "clf3  = GradientBoostingClassifier()\n",
        "clf4  = AdaBoostClassifier()\n",
        "\n",
        "\n",
        "eclf1 = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], weights=[2, 1, 1, 2], voting='soft')\n",
        "\n",
        "\n",
        "classifiers = [ eclf1]\n",
        "log = Fxn_CV(data, labels)\n",
        "print(log)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          Classifier Name   Acc (MS)  Acc-SD (MS)  AUROC (MS)  AUROC-SD (MS)  \\\n",
            "0  EnsembleVoteClassifier  96.661097     1.080601    0.994579        0.00284   \n",
            "\n",
            "         Acc  Acc-SD     AUROC  AUROC-SD  \n",
            "0  96.661097    1.25  0.958589     0.011  \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}